{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow pandas scipy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Na1xkusZLaD9",
        "outputId": "3bdc9d1a-540b-47d8-e085-f7eba95941b7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Collecting astunparse>=1.6.0 (from tensorflow)\n",
            "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
            "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Collecting google_pasta>=0.1.1 (from tensorflow)\n",
            "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
            "Collecting libclang>=13.0.0 (from tensorflow)\n",
            "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: opt_einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf>=5.28.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (6.32.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing_extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.74.0)\n",
            "Collecting tensorboard~=2.20.0 (from tensorflow)\n",
            "  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: keras>=3.10.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n",
            "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.10.0->tensorflow) (14.1.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.10.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard~=2.20.0->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.20.0->tensorflow) (11.3.0)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.20.0->tensorflow)\n",
            "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting werkzeug>=1.0.1 (from tensorboard~=2.20.0->tensorflow)\n",
            "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n",
            "Downloading tensorflow-2.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (620.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m620.7/620.7 MB\u001b[0m \u001b[31m857.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
            "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: libclang, flatbuffers, wheel, werkzeug, tensorboard-data-server, google_pasta, tensorboard, astunparse, tensorflow\n",
            "Successfully installed astunparse-1.6.3 flatbuffers-25.2.10 google_pasta-0.2.0 libclang-18.1.1 tensorboard-2.20.0 tensorboard-data-server-0.7.2 tensorflow-2.20.0 werkzeug-3.1.3 wheel-0.45.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3SQAupb2LB98",
        "outputId": "8fa612a8-8bc6-4254-8b5e-a240eed17a65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: /CPU:0\n",
            "Training starts...\n",
            "E[100/4000], L1:5.711e+04, L2:3.007e+03, Tot:6.011e+04, LR:5.00e-04\n",
            "E[200/4000], L1:1.544e+04, L2:4.357e+02, Tot:1.588e+04, LR:5.00e-04\n",
            "E[300/4000], L1:9.339e+03, L2:1.694e+02, Tot:9.509e+03, LR:5.00e-04\n",
            "E[400/4000], L1:4.516e+03, L2:1.412e+02, Tot:4.657e+03, LR:5.00e-04\n",
            "E[500/4000], L1:1.687e+03, L2:2.820e+02, Tot:1.969e+03, LR:5.00e-04\n",
            "E[600/4000], L1:1.309e+03, L2:3.570e+02, Tot:1.666e+03, LR:5.00e-04\n",
            "E[700/4000], L1:1.064e+03, L2:3.931e+02, Tot:1.457e+03, LR:5.00e-04\n",
            "E[800/4000], L1:8.608e+02, L2:4.267e+02, Tot:1.288e+03, LR:5.00e-04\n",
            "E[900/4000], L1:6.999e+02, L2:4.626e+02, Tot:1.163e+03, LR:5.00e-04\n",
            "E[1000/4000], L1:5.883e+02, L2:4.935e+02, Tot:1.082e+03, LR:4.80e-04\n",
            "E[1100/4000], L1:5.133e+02, L2:5.123e+02, Tot:1.026e+03, LR:4.80e-04\n",
            "E[1200/4000], L1:4.542e+02, L2:5.272e+02, Tot:9.814e+02, LR:4.80e-04\n",
            "E[1300/4000], L1:3.979e+02, L2:5.457e+02, Tot:9.436e+02, LR:4.80e-04\n",
            "E[1400/4000], L1:3.614e+02, L2:5.578e+02, Tot:9.191e+02, LR:4.80e-04\n",
            "E[1500/4000], L1:3.455e+02, L2:5.570e+02, Tot:9.025e+02, LR:4.80e-04\n",
            "E[1600/4000], L1:3.376e+02, L2:5.524e+02, Tot:8.900e+02, LR:4.80e-04\n",
            "E[1700/4000], L1:3.333e+02, L2:5.455e+02, Tot:8.788e+02, LR:4.80e-04\n",
            "E[1800/4000], L1:3.338e+02, L2:5.352e+02, Tot:8.690e+02, LR:4.80e-04\n",
            "E[1900/4000], L1:3.366e+02, L2:5.226e+02, Tot:8.593e+02, LR:4.80e-04\n",
            "E[2000/4000], L1:3.409e+02, L2:5.090e+02, Tot:8.499e+02, LR:4.61e-04\n",
            "E[2100/4000], L1:3.447e+02, L2:4.958e+02, Tot:8.405e+02, LR:4.61e-04\n",
            "E[2200/4000], L1:3.505e+02, L2:4.801e+02, Tot:8.306e+02, LR:4.61e-04\n",
            "E[2300/4000], L1:3.606e+02, L2:4.605e+02, Tot:8.211e+02, LR:4.61e-04\n",
            "E[2400/4000], L1:3.690e+02, L2:4.437e+02, Tot:8.127e+02, LR:4.61e-04\n",
            "E[2500/4000], L1:3.786e+02, L2:4.272e+02, Tot:8.058e+02, LR:4.61e-04\n",
            "E[2600/4000], L1:3.874e+02, L2:4.118e+02, Tot:7.992e+02, LR:4.61e-04\n",
            "E[2700/4000], L1:3.942e+02, L2:3.987e+02, Tot:7.929e+02, LR:4.61e-04\n",
            "E[2800/4000], L1:4.029e+02, L2:3.841e+02, Tot:7.870e+02, LR:4.61e-04\n",
            "E[2900/4000], L1:4.124e+02, L2:3.691e+02, Tot:7.814e+02, LR:4.61e-04\n",
            "E[3000/4000], L1:4.213e+02, L2:3.554e+02, Tot:7.768e+02, LR:4.42e-04\n",
            "E[3100/4000], L1:4.239e+02, L2:3.493e+02, Tot:7.732e+02, LR:4.42e-04\n",
            "E[3200/4000], L1:4.246e+02, L2:3.453e+02, Tot:7.699e+02, LR:4.42e-04\n",
            "E[3300/4000], L1:4.255e+02, L2:3.411e+02, Tot:7.666e+02, LR:4.42e-04\n",
            "E[3400/4000], L1:4.273e+02, L2:3.360e+02, Tot:7.634e+02, LR:4.42e-04\n",
            "E[3500/4000], L1:4.291e+02, L2:3.310e+02, Tot:7.602e+02, LR:4.42e-04\n",
            "E[3600/4000], L1:4.306e+02, L2:3.263e+02, Tot:7.569e+02, LR:4.42e-04\n",
            "E[3700/4000], L1:4.326e+02, L2:3.213e+02, Tot:7.538e+02, LR:4.42e-04\n",
            "E[3800/4000], L1:4.343e+02, L2:3.165e+02, Tot:7.508e+02, LR:4.42e-04\n",
            "E[3900/4000], L1:4.358e+02, L2:3.120e+02, Tot:7.477e+02, LR:4.42e-04\n",
            "E[4000/4000], L1:4.377e+02, L2:3.072e+02, Tot:7.448e+02, LR:4.25e-04\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Calculating contributions for uniaxial...\n",
            "  - Calculated contribution for term: Pow(I1)\n",
            "  - Calculated contribution for term: Pow(I2)\n",
            "  - Calculated contribution for term: Cosh(I1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function calculate_P11_task1_tf at 0x7f7cd93737e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  - Calculated contribution for term: Cosh(I2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function calculate_P11_task1_tf at 0x7f7cd93737e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  - Calculated contribution for term: Sinh(I1)\n",
            "  - Calculated contribution for term: Sinh(I2)\n",
            "  - Calculated contribution for term: Cosh(I4)\n",
            "  - Calculated contribution for term: Cosh(I6)\n",
            "  - Calculated contribution for term: Sinh(I4)\n",
            "  - Calculated contribution for term: Sinh(I6)\n",
            "\n",
            "Calculating contributions for biaxial...\n",
            "  - Calculated contribution for term: Pow(I1)\n",
            "  - Calculated contribution for term: Pow(I2)\n",
            "  - Calculated contribution for term: Cosh(I1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function calculate_P22_task2_tf_batch at 0x7f7cd9373e20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  - Calculated contribution for term: Cosh(I2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function calculate_P22_task2_tf_batch at 0x7f7cd9373e20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  - Calculated contribution for term: Sinh(I1)\n",
            "  - Calculated contribution for term: Sinh(I2)\n",
            "  - Calculated contribution for term: Cosh(I4)\n",
            "  - Calculated contribution for term: Cosh(I6)\n",
            "  - Calculated contribution for term: Sinh(I4)\n",
            "  - Calculated contribution for term: Sinh(I6)\n",
            "\n",
            "Successfully saved stress contributions to 'P_contributions_sinh_cosh_power.csv'\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from io import StringIO\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.io import savemat\n",
        "\n",
        "tf.keras.backend.set_floatx('float64')\n",
        "DEVICE = \"/GPU:0\" if tf.config.list_physical_devices('GPU') else \"/CPU:0\"\n",
        "print(f\"Using device: {DEVICE}\")\n",
        "\n",
        "ARG_CLIP_MIN = tf.constant(-10.0, dtype=tf.float64)\n",
        "ARG_CLIP_MAX = tf.constant(10.0, dtype=tf.float64)\n",
        "\n",
        "class StrainEnergyANN_Layered_TF(tf.keras.Model):\n",
        "    # ... (Your entire class definition remains exactly the same here) ...\n",
        "    def __init__(self):\n",
        "        super().__init__(name=\"StrainEnergyModel\")\n",
        "        # Power Law terms (I1, I2)\n",
        "        self.raw_log_k1=self.add_weight(name=\"raw_log_k1\",shape=(),dtype=tf.float64,initializer=tf.keras.initializers.RandomNormal(mean=0.0,stddev=0.01),trainable=True)\n",
        "        self.raw_log_k2=self.add_weight(name=\"raw_log_k2\",shape=(),dtype=tf.float64,initializer=tf.keras.initializers.RandomNormal(mean=0.0,stddev=0.01),trainable=True)\n",
        "        self.raw_log_i1=self.add_weight(name=\"raw_log_i1\",shape=(),dtype=tf.float64,initializer=tf.keras.initializers.RandomNormal(mean=0.0,stddev=0.01),trainable=True)\n",
        "        self.raw_log_i2=self.add_weight(name=\"raw_log_i2\",shape=(),dtype=tf.float64,initializer=tf.keras.initializers.RandomNormal(mean=0.0,stddev=0.01),trainable=True)\n",
        "        self.raw_log_a1=self.add_weight(name=\"raw_log_a1\",shape=(),dtype=tf.float64,initializer=tf.keras.initializers.Constant(tf.math.log(0.1)),trainable=True)\n",
        "        self.raw_log_a2=self.add_weight(name=\"raw_log_a2\",shape=(),dtype=tf.float64,initializer=tf.keras.initializers.Constant(tf.math.log(0.1)),trainable=True)\n",
        "\n",
        "        # Cosh with i terms (I1, I2)\n",
        "        self.raw_log_k5=self.add_weight(name=\"raw_log_k5\",shape=(),dtype=tf.float64,initializer=tf.keras.initializers.RandomNormal(mean=0.0,stddev=0.01),trainable=True)\n",
        "        self.raw_log_k6=self.add_weight(name=\"raw_log_k6\",shape=(),dtype=tf.float64,initializer=tf.keras.initializers.RandomNormal(mean=0.0,stddev=0.01),trainable=True)\n",
        "        self.raw_log_i5=self.add_weight(name=\"raw_log_i5\",shape=(),dtype=tf.float64,initializer=tf.keras.initializers.RandomNormal(mean=0.0,stddev=0.01),trainable=True)\n",
        "        self.raw_log_i6=self.add_weight(name=\"raw_log_i6\",shape=(),dtype=tf.float64,initializer=tf.keras.initializers.RandomNormal(mean=0.0,stddev=0.01),trainable=True)\n",
        "        self.raw_log_a5=self.add_weight(name=\"raw_log_a5\",shape=(),dtype=tf.float64,initializer=tf.keras.initializers.Constant(tf.math.log(0.1)),trainable=True)\n",
        "        self.raw_log_a6=self.add_weight(name=\"raw_log_a6\",shape=(),dtype=tf.float64,initializer=tf.keras.initializers.Constant(tf.math.log(0.1)),trainable=True)\n",
        "        self.raw_log_a5_prime=self.add_weight(name=\"raw_log_a5_prime\",shape=(),dtype=tf.float64,initializer=tf.keras.initializers.Constant(tf.math.log(0.2)),trainable=True)\n",
        "        self.raw_log_a6_prime=self.add_weight(name=\"raw_log_a6_prime\",shape=(),dtype=tf.float64,initializer=tf.keras.initializers.Constant(tf.math.log(0.2)),trainable=True)\n",
        "\n",
        "        # Sinh with i terms (I1, I2)\n",
        "        self.raw_log_k7=self.add_weight(name=\"raw_log_k7\",shape=(),dtype=tf.float64,initializer=tf.keras.initializers.RandomNormal(mean=0.0,stddev=0.01),trainable=True)\n",
        "        self.raw_log_k8=self.add_weight(name=\"raw_log_k8\",shape=(),dtype=tf.float64,initializer=tf.keras.initializers.RandomNormal(mean=0.0,stddev=0.01),trainable=True)\n",
        "        self.raw_log_i7=self.add_weight(name=\"raw_log_i7\",shape=(),dtype=tf.float64,initializer=tf.keras.initializers.RandomNormal(mean=0.0,stddev=0.01),trainable=True)\n",
        "        self.raw_log_i8=self.add_weight(name=\"raw_log_i8\",shape=(),dtype=tf.float64,initializer=tf.keras.initializers.RandomNormal(mean=0.0,stddev=0.01),trainable=True)\n",
        "        self.raw_log_a7=self.add_weight(name=\"raw_log_a7\",shape=(),dtype=tf.float64,initializer=tf.keras.initializers.Constant(tf.math.log(0.1)),trainable=True)\n",
        "        self.raw_log_a8=self.add_weight(name=\"raw_log_a8\",shape=(),dtype=tf.float64,initializer=tf.keras.initializers.Constant(tf.math.log(0.1)),trainable=True)\n",
        "        self.raw_log_a7_prime=self.add_weight(name=\"raw_log_a7_prime\",shape=(),dtype=tf.float64,initializer=tf.keras.initializers.Constant(tf.math.log(0.2)),trainable=True)\n",
        "        self.raw_log_a8_prime=self.add_weight(name=\"raw_log_a8_prime\",shape=(),dtype=tf.float64,initializer=tf.keras.initializers.Constant(tf.math.log(0.2)),trainable=True)\n",
        "\n",
        "        # Cosh terms (I4, I6)\n",
        "        self.raw_log_k13=self.add_weight(name=\"raw_log_k13\",shape=(),dtype=tf.float64,initializer=tf.keras.initializers.RandomNormal(mean=0.0,stddev=0.01),trainable=True)\n",
        "        self.raw_log_k14=self.add_weight(name=\"raw_log_k14\",shape=(),dtype=tf.float64,initializer=tf.keras.initializers.RandomNormal(mean=0.0,stddev=0.01),trainable=True)\n",
        "        self.raw_log_b5=self.add_weight(name=\"raw_log_b5\",shape=(),dtype=tf.float64,initializer=tf.keras.initializers.Constant(tf.math.log(0.1)),trainable=True)\n",
        "        self.raw_log_b6=self.add_weight(name=\"raw_log_b6\",shape=(),dtype=tf.float64,initializer=tf.keras.initializers.Constant(tf.math.log(0.1)),trainable=True)\n",
        "        self.raw_log_b5_prime=self.add_weight(name=\"raw_log_b5_prime\",shape=(),dtype=tf.float64,initializer=tf.keras.initializers.Constant(tf.math.log(0.2)),trainable=True)\n",
        "        self.raw_log_b6_prime=self.add_weight(name=\"raw_log_b6_prime\",shape=(),dtype=tf.float64,initializer=tf.keras.initializers.Constant(tf.math.log(0.2)),trainable=True)\n",
        "\n",
        "        # Sinh terms (I4, I6)\n",
        "        self.raw_log_k15=self.add_weight(name=\"raw_log_k15\",shape=(),dtype=tf.float64,initializer=tf.keras.initializers.RandomNormal(mean=0.0,stddev=0.01),trainable=True)\n",
        "        self.raw_log_k16=self.add_weight(name=\"raw_log_k16\",shape=(),dtype=tf.float64,initializer=tf.keras.initializers.RandomNormal(mean=0.0,stddev=0.01),trainable=True)\n",
        "        self.raw_log_b7=self.add_weight(name=\"raw_log_b7\",shape=(),dtype=tf.float64,initializer=tf.keras.initializers.Constant(tf.math.log(0.1)),trainable=True)\n",
        "        self.raw_log_b8=self.add_weight(name=\"raw_log_b8\",shape=(),dtype=tf.float64,initializer=tf.keras.initializers.Constant(tf.math.log(0.1)),trainable=True)\n",
        "        self.raw_log_b7_prime=self.add_weight(name=\"raw_log_b7_prime\",shape=(),dtype=tf.float64,initializer=tf.keras.initializers.Constant(tf.math.log(0.2)),trainable=True)\n",
        "        self.raw_log_b8_prime=self.add_weight(name=\"raw_log_b8_prime\",shape=(),dtype=tf.float64,initializer=tf.keras.initializers.Constant(tf.math.log(0.2)),trainable=True)\n",
        "\n",
        "        self.three=tf.constant(3.0,dtype=tf.float64); self.one=tf.constant(1.0,dtype=tf.float64); self.pow_base_epsilon=tf.constant(1e-8,dtype=tf.float64)\n",
        "\n",
        "    def _term_power_law(self, I, k, i, c, ref_val): return c * tf.pow(tf.maximum(tf.pow(I, k) - tf.pow(ref_val, k), 0.0) + self.pow_base_epsilon, i)\n",
        "    def _term_cosh_minus_one_with_i(self, I, k, i, ic, oc, ref_val): return oc * (tf.cosh(tf.clip_by_value(ic * tf.pow(tf.maximum(tf.pow(I, k) - tf.pow(ref_val, k), 0.0) + self.pow_base_epsilon, i), ARG_CLIP_MIN, ARG_CLIP_MAX)) - 1.0)\n",
        "    def _term_sinh_with_i(self, I, k, i, ic, oc, ref_val): return oc * tf.sinh(tf.clip_by_value(ic * tf.pow(tf.maximum(tf.pow(I, k) - tf.pow(ref_val, k), 0.0) + self.pow_base_epsilon, i), ARG_CLIP_MIN, ARG_CLIP_MAX))\n",
        "    def _term_cosh_minus_one(self, I, k, ic, oc, ref_val): return oc * (tf.cosh(tf.clip_by_value(ic * (tf.pow(I, k) - tf.pow(ref_val, k)), ARG_CLIP_MIN, ARG_CLIP_MAX)) - 1.0)\n",
        "    def _term_sinh(self, I, k, ic, oc, ref_val): return oc * tf.sinh(tf.clip_by_value(ic * (tf.pow(I, k) - tf.pow(ref_val, k)), ARG_CLIP_MIN, ARG_CLIP_MAX))\n",
        "\n",
        "    def call(self, I1, I2, I4, I6):\n",
        "        k1=1.0+tf.exp(self.raw_log_k1);k2=1.5+tf.exp(self.raw_log_k2);k5=1.0+tf.exp(self.raw_log_k5);k6=1.5+tf.exp(self.raw_log_k6);k7=1.0+tf.exp(self.raw_log_k7);k8=1.5+tf.exp(self.raw_log_k8);k13=1.0+tf.exp(self.raw_log_k13);k14=1.5+tf.exp(self.raw_log_k14);k15=1.0+tf.exp(self.raw_log_k15);k16=1.5+tf.exp(self.raw_log_k16)\n",
        "        i1=1.0+tf.exp(self.raw_log_i1);i2=1.0+tf.exp(self.raw_log_i2);i5=1.0+tf.exp(self.raw_log_i5);i6=1.0+tf.exp(self.raw_log_i6);i7=1.0+tf.exp(self.raw_log_i7);i8=1.0+tf.exp(self.raw_log_i8)\n",
        "        a1=tf.exp(self.raw_log_a1);a2=tf.exp(self.raw_log_a2);a5=tf.exp(self.raw_log_a5);a6=tf.exp(self.raw_log_a6);a7=tf.exp(self.raw_log_a7);a8=tf.exp(self.raw_log_a8)\n",
        "        a5_prime=tf.exp(self.raw_log_a5_prime);a6_prime=tf.exp(self.raw_log_a6_prime);a7_prime=tf.exp(self.raw_log_a7_prime);a8_prime=tf.exp(self.raw_log_a8_prime)\n",
        "        b5=tf.exp(self.raw_log_b5);b6=tf.exp(self.raw_log_b6);b7=tf.exp(self.raw_log_b7);b8=tf.exp(self.raw_log_b8)\n",
        "        b5_prime=tf.exp(self.raw_log_b5_prime);b6_prime=tf.exp(self.raw_log_b6_prime);b7_prime=tf.exp(self.raw_log_b7_prime);b8_prime=tf.exp(self.raw_log_b8_prime)\n",
        "\n",
        "        W = tf.zeros_like(I1,dtype=tf.float64)\n",
        "        W += self._term_power_law(I1,k1,i1,a1,self.three); W += self._term_power_law(I2,k2,i2,a2,self.three)\n",
        "        W += self._term_cosh_minus_one_with_i(I1,k5,i5,a5_prime,a5,self.three); W += self._term_cosh_minus_one_with_i(I2,k6,i6,a6_prime,a6,self.three)\n",
        "        W += self._term_sinh_with_i(I1,k7,i7,a7_prime,a7,self.three); W += self._term_sinh_with_i(I2,k8,i8,a8_prime,a8,self.three)\n",
        "        W += self._term_cosh_minus_one(I4,k13,b5_prime,b5,self.one); W += self._term_cosh_minus_one(I6,k14,b6_prime,b6,self.one)\n",
        "        W += self._term_sinh(I4,k15,b7_prime,b7,self.one); W += self._term_sinh(I6,k16,b8_prime,b8,self.one)\n",
        "        return W\n",
        "\n",
        "# ... (All the original stress calculation functions remain the same) ...\n",
        "# ... (get_invariants_tf, get_W_and_gradients_tf, calculate_P11_task1_tf, etc.) ...\n",
        "@tf.function\n",
        "def get_invariants_tf(lambda1,lambda2,lambda3):\n",
        "    min_lambda_val=tf.constant(1e-4,dtype=tf.float64); lambda1=tf.maximum(lambda1,min_lambda_val); lambda2=tf.maximum(lambda2,min_lambda_val); lambda3=tf.maximum(lambda3,min_lambda_val); l1s=tf.pow(lambda1,2.0); l2s=tf.pow(lambda2,2.0); l3s=tf.pow(lambda3,2.0)\n",
        "    I1=l1s+l2s+l3s; I2=tf.pow(lambda1*lambda2,2.0)+tf.pow(lambda2*lambda3,2.0)+tf.pow(lambda3*lambda1,2.0); I4=l1s; I6=tf.pow(lambda1,-2.0)\n",
        "    return I1,I2,I4,I6\n",
        "@tf.function\n",
        "def get_W_and_gradients_tf(l1t,l2t,l3t,model, W_func):\n",
        "    with tf.GradientTape(watch_accessed_variables=False) as tape:\n",
        "        tape.watch([l1t, l2t, l3t]); I1, I2, I4, I6 = get_invariants_tf(l1t, l2t, l3t); W_val = W_func(I1, I2, I4, I6)\n",
        "    grads = tape.gradient(W_val, [l1t, l2t, l3t]); dWdl1 = grads[0] if grads[0] is not None else tf.zeros_like(l1t); dWdl2 = grads[1] if grads[1] is not None else tf.zeros_like(l2t); dWdl3 = grads[2] if grads[2] is not None else tf.zeros_like(l3t)\n",
        "    return W_val, dWdl1, dWdl2, dWdl3\n",
        "@tf.function\n",
        "def _calculate_raw_P11_task1_tf(l1vst, model, W_func):\n",
        "    l1t = tf.maximum(l1vst, tf.constant(1e-4, dtype=tf.float64))\n",
        "    l2t = tf.pow(l1t, -0.5)\n",
        "    l3t = tf.pow(l1t, -0.5)\n",
        "    _, dWdl1, _, dWdl3 = get_W_and_gradients_tf(l1t, l2t, l3t, model, W_func)\n",
        "    Ph = l3t * dWdl3\n",
        "    safe_l1t = tf.maximum(l1t, tf.constant(1e-6, dtype=tf.float64))\n",
        "    return (dWdl1 - Ph / safe_l1t) / 7.5\n",
        "@tf.function\n",
        "def calculate_P11_task1_tf(l1vst, model, W_func):\n",
        "    p11_raw = _calculate_raw_P11_task1_tf(l1vst, model, W_func)\n",
        "    p11_offset = _calculate_raw_P11_task1_tf(tf.constant([1.0], dtype=tf.float64), model, W_func)\n",
        "    return p11_raw - p11_offset\n",
        "\n",
        "@tf.function\n",
        "def sigma11_for_root_tf(lambda1_trial_t, lambda2_fixed_t_tensor, model, W_func):\n",
        "    lambda1_trial_t_stable = tf.maximum(lambda1_trial_t, tf.constant(1e-4, dtype=tf.float64)); lambda2_fixed_t_stable = tf.maximum(lambda2_fixed_t_tensor, tf.constant(1e-4, dtype=tf.float64))\n",
        "    safe_denom_prod = tf.maximum(lambda1_trial_t_stable * lambda2_fixed_t_stable, tf.constant(1e-6, dtype=tf.float64)); lambda3_trial_t = (1.0 / safe_denom_prod)\n",
        "    _, dW_dlambda1, _, dW_dlambda3 = get_W_and_gradients_tf(lambda1_trial_t_stable, lambda2_fixed_t_stable, lambda3_trial_t, model, W_func); P_hydro = lambda3_trial_t * dW_dlambda3\n",
        "    safe_lambda1_trial_t_stable = tf.maximum(lambda1_trial_t_stable, tf.constant(1e-6, dtype=tf.float64)); return (dW_dlambda1 - P_hydro / safe_lambda1_trial_t_stable)\n",
        "\n",
        "@tf.function\n",
        "def find_lambda1_newton_tf(lambda2_val_scalar_tensor, model, W_func, initial_lambda1_guess=1.0, iterations=tf.constant(10, dtype=tf.int32), tol=1e-7):\n",
        "    min_lambda_val_newton=tf.constant(0.2,dtype=tf.float64); max_lambda_val_newton=tf.constant(3.0,dtype=tf.float64); max_step_lambda=tf.constant(0.1,dtype=tf.float64)\n",
        "    loop_vars = [tf.constant(0, dtype=tf.int32), initial_lambda1_guess, tf.constant(False, dtype=tf.bool)]\n",
        "    def cond(i, _, converged): return tf.logical_and(i < iterations, tf.logical_not(converged))\n",
        "    def body(i, current_lambda, _):\n",
        "        with tf.GradientTape(watch_accessed_variables=False) as tape:\n",
        "            tape.watch(current_lambda); sigma11 = sigma11_for_root_tf(current_lambda, lambda2_val_scalar_tensor, model, W_func)\n",
        "        grad = tape.gradient(sigma11, current_lambda); newly_converged = tf.abs(sigma11) < tol\n",
        "        problem = grad is None or tf.math.is_nan(grad) or tf.math.is_inf(grad)\n",
        "        def update_lambda():\n",
        "            delta = sigma11 / (grad + tf.constant(1e-8, dtype=tf.float64) * tf.sign(grad)); problem_delta = tf.math.is_nan(delta) or tf.math.is_inf(delta)\n",
        "            safe_delta = tf.cond(problem_delta, lambda: tf.constant(0.0, dtype=tf.float64), lambda: delta); clipped_delta = tf.clip_by_value(safe_delta, -max_step_lambda, max_step_lambda)\n",
        "            return tf.clip_by_value(current_lambda - clipped_delta, min_lambda_val_newton, max_lambda_val_newton)\n",
        "        next_lambda = tf.cond(problem, lambda: current_lambda, update_lambda); return [i + 1, next_lambda, tf.logical_or(newly_converged, problem)]\n",
        "    _, final_lambda, _ = tf.while_loop(cond, body, loop_vars); return final_lambda\n",
        "\n",
        "@tf.function\n",
        "def _calculate_raw_P22_task2_tf(lambda2_val_scalar_tensor, model, W_func):\n",
        "    lambda2_stable = tf.maximum(lambda2_val_scalar_tensor, tf.constant(1e-4, dtype=tf.float64))\n",
        "    initial_lambda1_guess = 1.0 / tf.sqrt(lambda2_stable)\n",
        "    lambda1_root_t = find_lambda1_newton_tf(lambda2_stable, model, W_func, initial_lambda1_guess)\n",
        "    lambda1_root_t_stable = tf.maximum(lambda1_root_t, tf.constant(1e-4, dtype=tf.float64))\n",
        "    safe_denom = tf.maximum(lambda1_root_t_stable * lambda2_stable, tf.constant(1e-6, dtype=tf.float64))\n",
        "    lambda3_calc_t = (1.0 / safe_denom)\n",
        "    _, _, dWdl2, dWdl3 = get_W_and_gradients_tf(lambda1_root_t_stable, lambda2_stable, lambda3_calc_t, model, W_func)\n",
        "    Ph = lambda3_calc_t * dWdl3\n",
        "    safe_lambda2_calc_t = tf.maximum(lambda2_stable, tf.constant(1e-6, dtype=tf.float64))\n",
        "    return (dWdl2 - Ph / safe_lambda2_calc_t) / 50\n",
        "@tf.function\n",
        "def calculate_P22_task2_tf_batch(lambda2_batch, model, W_func):\n",
        "    p22_raw_batch = tf.scan(lambda _, l2: _calculate_raw_P22_task2_tf(l2, model, W_func), lambda2_batch, initializer=tf.constant(0.0, dtype=tf.float64))\n",
        "    p22_offset = _calculate_raw_P22_task2_tf(tf.constant(1.0, dtype=tf.float64), model, W_func)\n",
        "    return p22_raw_batch - p22_offset\n",
        "\n",
        "# ... (Data Loading and Normalization remain the same) ...\n",
        "exp_data_raw_uniaxial_cnf=np.array([[1.1986196319018403,1.285990338164251],[1.18680981595092,0.9768115942028984],[1.1699386503067484,0.638647342995169],[1.1483128834355827,0.29275362318840586],[1.1153374233128834,0.08502415458937207],[1.0725460122699388,0.018357487922705418],[1.040184049079755,0.00869565217391316],[1.0157975460122703,0.0019323671497585848],[1.0,0.0]])\n",
        "lambda1_data_task1_np=exp_data_raw_uniaxial_cnf[:,0]; P11_data_task1_np=exp_data_raw_uniaxial_cnf[:,1]\n",
        "csv_content_cnf=\"lambda,stress\\n1.1917177914110426,0.16038647342995177\\n1.1464723926380367,0.056038647342995296\\n1.108435582822086,0.028019323671497676\\n1.071472392638037,0.013526570048309317\\n1.038343558282209,0.006763285024154686\\n1.0,0.0\\n\"\n",
        "df_task2=pd.read_csv(StringIO(csv_content_cnf)); lambda2_data_task2_np=df_task2['lambda'].values; P22_data_task2_np=df_task2['stress'].values\n",
        "stress_scale = max(np.max(P11_data_task1_np), np.max(P22_data_task2_np))\n",
        "P11_data_task1_norm_np = P11_data_task1_np / stress_scale\n",
        "P22_data_task2_norm_np = P22_data_task2_np / stress_scale\n",
        "stress_scale_tf = tf.constant(stress_scale, dtype=tf.float64)\n",
        "lambda1_data_task1_tf=tf.constant(lambda1_data_task1_np,dtype=tf.float64)\n",
        "P11_data_task1_norm_tf=tf.constant(P11_data_task1_norm_np,dtype=tf.float64)\n",
        "lambda2_data_task2_tf=tf.constant(lambda2_data_task2_np,dtype=tf.float64)\n",
        "P22_data_task2_norm_tf=tf.constant(P22_data_task2_norm_np,dtype=tf.float64)\n",
        "\n",
        "# --- Model, Optimizer, and Training Setup remain the same ---\n",
        "model_tf_layered = StrainEnergyANN_Layered_TF()\n",
        "L2_REG_STRENGTH = tf.constant(1e-12, dtype=tf.float64)\n",
        "POSITIVITY_PENALTY_STRENGTH = tf.constant(5e4, dtype=tf.float64)\n",
        "initial_learning_rate = 5e-4\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate, decay_steps=1000, decay_rate=0.96, staircase=True)\n",
        "optimizer_tf = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "\n",
        "@tf.function\n",
        "def train_step_final(l1_batch, p11_batch_norm, l2_batch, p22_batch_norm, model, scale_factor, l2_reg, pos_penalty_strength):\n",
        "    with tf.GradientTape() as tape:\n",
        "        p11_pred = calculate_P11_task1_tf(l1_batch, model, model.call)\n",
        "        p22_pred = calculate_P22_task2_tf_batch(l2_batch, model, model.call)\n",
        "\n",
        "        p11_pred_norm = p11_pred / scale_factor\n",
        "        p22_pred_norm = p22_pred / scale_factor\n",
        "\n",
        "        loss1_weight = 2500000.0\n",
        "        loss2_weight = 10000000.0\n",
        "        loss1 = tf.reduce_mean(tf.square(p11_batch_norm - p11_pred_norm)) * loss1_weight\n",
        "        loss2 = tf.reduce_mean(tf.square(p22_batch_norm - p22_pred_norm)) * loss2_weight\n",
        "\n",
        "        positivity_loss_1 = tf.reduce_mean(tf.nn.relu(-p11_pred))\n",
        "        positivity_loss_2 = tf.reduce_mean(tf.nn.relu(-p22_pred))\n",
        "        l2_loss = tf.add_n([tf.nn.l2_loss(v) for v in model.trainable_variables])\n",
        "        total_loss = (loss1 + loss2 +\n",
        "                      l2_reg * l2_loss +\n",
        "                      pos_penalty_strength * (positivity_loss_1 + positivity_loss_2))\n",
        "    t_vars = model.trainable_variables\n",
        "    grads = tape.gradient(total_loss, t_vars)\n",
        "    optimizer_tf.apply_gradients(zip([tf.clip_by_norm(g, 1.0) if g is not None else tf.zeros_like(v) for g, v in zip(grads, t_vars)], t_vars))\n",
        "    return loss1, loss2, total_loss\n",
        "\n",
        "# --- Training Loop remains the same ---\n",
        "epochs=4000\n",
        "dI1=tf.constant([3.0],dtype=tf.float64); dI2=tf.constant([3.0],dtype=tf.float64); dI4=tf.constant([1.0],dtype=tf.float64); dI6=tf.constant([1.e-6],dtype=tf.float64)\n",
        "_=model_tf_layered(dI1,dI2,dI4,dI6)\n",
        "print(\"Training starts...\");\n",
        "for e in range(epochs):\n",
        "    l1,l2,tl=train_step_final(lambda1_data_task1_tf, P11_data_task1_norm_tf, lambda2_data_task2_tf, P22_data_task2_norm_tf,\n",
        "                              model_tf_layered, stress_scale_tf, L2_REG_STRENGTH, POSITIVITY_PENALTY_STRENGTH)\n",
        "    if (e+1)%100==0:\n",
        "        current_lr = lr_schedule(optimizer_tf.iterations).numpy()\n",
        "        print(f\"E[{e+1}/{epochs}], L1:{l1.numpy():.3e}, L2:{l2.numpy():.3e}, Tot:{tl.numpy():.3e}, LR:{current_lr:.2e}\")\n",
        "\n",
        "# ... (Standard plotting code remains the same) ...\n",
        "# The data for plotting is generated here\n",
        "l1_plot = np.linspace(lambda1_data_task1_np.min(), lambda1_data_task1_np.max(), 100)\n",
        "p11_plot = calculate_P11_task1_tf(tf.constant(l1_plot, dtype=tf.float64), model_tf_layered, model_tf_layered.call).numpy()\n",
        "l2_plot = np.linspace(lambda2_data_task2_np.min(), lambda2_data_task2_np.max(), 100)\n",
        "p22_plot = calculate_P22_task2_tf_batch(tf.constant(l2_plot, dtype=tf.float64), model_tf_layered, model_tf_layered.call).numpy()\n",
        "\n",
        "# Plotting the final results\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.scatter(lambda1_data_task1_np, P11_data_task1_np, c='b', label='Actual P11')\n",
        "plt.plot(l1_plot, p11_plot, c='r', label='Predicted P11')\n",
        "plt.scatter(lambda2_data_task2_np, P22_data_task2_np, c='g', marker='x', label='Actual P22')\n",
        "plt.plot(l2_plot, p22_plot, c='orange', label='Predicted P22')\n",
        "plt.legend(); plt.grid(True); plt.xlabel(r\"$\\lambda$\"); plt.ylabel(\"Stress\"); plt.show()\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# ===== NEW SECTION: CALCULATE AND SAVE STRESS CONTRIBUTIONS ===================\n",
        "# ==============================================================================\n",
        "\n",
        "def get_model_terms(model):\n",
        "    \"\"\"Returns a dictionary of individual W term functions from the model.\"\"\"\n",
        "    # This function is long but just mirrors the structure of the `call` function\n",
        "    k1=1.0+tf.exp(model.raw_log_k1);k2=1.5+tf.exp(model.raw_log_k2);k5=1.0+tf.exp(model.raw_log_k5);k6=1.5+tf.exp(model.raw_log_k6);k7=1.0+tf.exp(model.raw_log_k7);k8=1.5+tf.exp(model.raw_log_k8);k13=1.0+tf.exp(model.raw_log_k13);k14=1.5+tf.exp(model.raw_log_k14);k15=1.0+tf.exp(model.raw_log_k15);k16=1.5+tf.exp(model.raw_log_k16)\n",
        "    i1=1.0+tf.exp(model.raw_log_i1);i2=1.0+tf.exp(model.raw_log_i2);i5=1.0+tf.exp(model.raw_log_i5);i6=1.0+tf.exp(model.raw_log_i6);i7=1.0+tf.exp(model.raw_log_i7);i8=1.0+tf.exp(model.raw_log_i8)\n",
        "    a1=tf.exp(model.raw_log_a1);a2=tf.exp(model.raw_log_a2);a5=tf.exp(model.raw_log_a5);a6=tf.exp(model.raw_log_a6);a7=tf.exp(model.raw_log_a7);a8=tf.exp(model.raw_log_a8)\n",
        "    a5_prime=tf.exp(model.raw_log_a5_prime);a6_prime=tf.exp(model.raw_log_a6_prime);a7_prime=tf.exp(model.raw_log_a7_prime);a8_prime=tf.exp(model.raw_log_a8_prime)\n",
        "    b5=tf.exp(model.raw_log_b5);b6=tf.exp(model.raw_log_b6);b7=tf.exp(model.raw_log_b7);b8=tf.exp(model.raw_log_b8)\n",
        "    b5_prime=tf.exp(model.raw_log_b5_prime);b6_prime=tf.exp(model.raw_log_b6_prime);b7_prime=tf.exp(model.raw_log_b7_prime);b8_prime=tf.exp(model.raw_log_b8_prime)\n",
        "\n",
        "    terms = {\n",
        "        \"Pow(I1)\":   lambda I1, I2, I4, I6: model._term_power_law(I1,k1,i1,a1,model.three),\n",
        "        \"Pow(I2)\":   lambda I1, I2, I4, I6: model._term_power_law(I2,k2,i2,a2,model.three),\n",
        "        \"Cosh(I1)\":  lambda I1, I2, I4, I6: model._term_cosh_minus_one_with_i(I1,k5,i5,a5_prime,a5,model.three),\n",
        "        \"Cosh(I2)\":  lambda I1, I2, I4, I6: model._term_cosh_minus_one_with_i(I2,k6,i6,a6_prime,a6,model.three),\n",
        "        \"Sinh(I1)\":  lambda I1, I2, I4, I6: model._term_sinh_with_i(I1,k7,i7,a7_prime,a7,model.three),\n",
        "        \"Sinh(I2)\":  lambda I1, I2, I4, I6: model._term_sinh_with_i(I2,k8,i8,a8_prime,a8,model.three),\n",
        "        \"Cosh(I4)\":  lambda I1, I2, I4, I6: model._term_cosh_minus_one(I4,k13,b5_prime,b5,model.one),\n",
        "        \"Cosh(I6)\":  lambda I1, I2, I4, I6: model._term_cosh_minus_one(I6,k14,b6_prime,b6,model.one),\n",
        "        \"Sinh(I4)\":  lambda I1, I2, I4, I6: model._term_sinh(I4,k15,b7_prime,b7,model.one),\n",
        "        \"Sinh(I6)\":  lambda I1, I2, I4, I6: model._term_sinh(I6,k16,b8_prime,b8,model.one),\n",
        "    }\n",
        "    return terms\n",
        "\n",
        "def calculate_stress_contributions(lambda_values, model, task_type):\n",
        "    \"\"\"Calculates the stress contribution of each term in the model.\"\"\"\n",
        "    terms = get_model_terms(model)\n",
        "    contributions = {}\n",
        "\n",
        "    print(f\"\\nCalculating contributions for {task_type}...\")\n",
        "\n",
        "    for name, W_func in terms.items():\n",
        "        if task_type == 'uniaxial':\n",
        "            stress_contribution = calculate_P11_task1_tf(lambda_values, model, W_func)\n",
        "        elif task_type == 'biaxial':\n",
        "            stress_contribution = calculate_P22_task2_tf_batch(lambda_values, model, W_func)\n",
        "        else:\n",
        "            raise ValueError(\"task_type must be 'uniaxial' or 'biaxial'\")\n",
        "\n",
        "        contributions[name] = stress_contribution.numpy()\n",
        "        print(f\"  - Calculated contribution for term: {name}\")\n",
        "\n",
        "    return contributions\n",
        "\n",
        "# Define smooth lambda ranges for plotting\n",
        "lambda1_plot_tf = tf.constant(np.linspace(1.0, 1.2, 100), dtype=tf.float64)\n",
        "lambda2_plot_tf = tf.constant(np.linspace(1.0, 1.2, 100), dtype=tf.float64)\n",
        "\n",
        "# Calculate contributions for both tasks\n",
        "p11_contributions = calculate_stress_contributions(lambda1_plot_tf, model_tf_layered, 'uniaxial')\n",
        "p22_contributions = calculate_stress_contributions(lambda2_plot_tf, model_tf_layered, 'biaxial')\n",
        "\n",
        "# Create a single DataFrame to hold all the data\n",
        "df_contrib = pd.DataFrame()\n",
        "df_contrib['lambda1'] = lambda1_plot_tf.numpy()\n",
        "for name, values in p11_contributions.items():\n",
        "    df_contrib[f'P11_{name}'] = values\n",
        "\n",
        "df_contrib['lambda2'] = lambda2_plot_tf.numpy()\n",
        "for name, values in p22_contributions.items():\n",
        "    df_contrib[f'P22_{name}'] = values\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "output_filename = 'P_contributions_sinh_cosh_power.csv'\n",
        "df_contrib.to_csv(output_filename, index=False)\n",
        "\n",
        "print(f\"\\nSuccessfully saved stress contributions to '{output_filename}'\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# ===== NEW SECTION: EXTRACT AND PRINT FINAL LEARNED PARAMETERS ==============\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"      Final Learned Model Parameters (Raw Log Form)\")\n",
        "print(\"=\"*60)\n",
        "# This prints the raw values that the optimizer sees.\n",
        "for v in model_tf_layered.trainable_variables:\n",
        "    print(f\"{v.name:20s}: {v.numpy():.8f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"   Transformed Model Parameters (Physical Interpretable Values)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# --- k parameters (exponents) ---\n",
        "# Note the different base values (1.0 or 1.5) as defined in your model\n",
        "k1 = 1.0 + tf.exp(model_tf_layered.raw_log_k1).numpy()\n",
        "k2 = 1.5 + tf.exp(model_tf_layered.raw_log_k2).numpy()\n",
        "k5 = 1.0 + tf.exp(model_tf_layered.raw_log_k5).numpy()\n",
        "k6 = 1.5 + tf.exp(model_tf_layered.raw_log_k6).numpy()\n",
        "k7 = 1.0 + tf.exp(model_tf_layered.raw_log_k7).numpy()\n",
        "k8 = 1.5 + tf.exp(model_tf_layered.raw_log_k8).numpy()\n",
        "k13 = 1.0 + tf.exp(model_tf_layered.raw_log_k13).numpy()\n",
        "k14 = 1.5 + tf.exp(model_tf_layered.raw_log_k14).numpy()\n",
        "k15 = 1.0 + tf.exp(model_tf_layered.raw_log_k15).numpy()\n",
        "k16 = 1.5 + tf.exp(model_tf_layered.raw_log_k16).numpy()\n",
        "\n",
        "# --- i parameters (exponents) ---\n",
        "i1 = 1.0 + tf.exp(model_tf_layered.raw_log_i1).numpy()\n",
        "i2 = 1.0 + tf.exp(model_tf_layered.raw_log_i2).numpy()\n",
        "i5 = 1.0 + tf.exp(model_tf_layered.raw_log_i5).numpy()\n",
        "i6 = 1.0 + tf.exp(model_tf_layered.raw_log_i6).numpy()\n",
        "i7 = 1.0 + tf.exp(model_tf_layered.raw_log_i7).numpy()\n",
        "i8 = 1.0 + tf.exp(model_tf_layered.raw_log_i8).numpy()\n",
        "\n",
        "# --- a parameters (coefficients for I1, I2 terms) ---\n",
        "a1 = tf.exp(model_tf_layered.raw_log_a1).numpy()\n",
        "a2 = tf.exp(model_tf_layered.raw_log_a2).numpy()\n",
        "a5 = tf.exp(model_tf_layered.raw_log_a5).numpy()\n",
        "a6 = tf.exp(model_tf_layered.raw_log_a6).numpy()\n",
        "a7 = tf.exp(model_tf_layered.raw_log_a7).numpy()\n",
        "a8 = tf.exp(model_tf_layered.raw_log_a8).numpy()\n",
        "a5_prime = tf.exp(model_tf_layered.raw_log_a5_prime).numpy()\n",
        "a6_prime = tf.exp(model_tf_layered.raw_log_a6_prime).numpy()\n",
        "a7_prime = tf.exp(model_tf_layered.raw_log_a7_prime).numpy()\n",
        "a8_prime = tf.exp(model_tf_layered.raw_log_a8_prime).numpy()\n",
        "\n",
        "# --- b parameters (coefficients for I4, I6 terms) ---\n",
        "b5 = tf.exp(model_tf_layered.raw_log_b5).numpy()\n",
        "b6 = tf.exp(model_tf_layered.raw_log_b6).numpy()\n",
        "b7 = tf.exp(model_tf_layered.raw_log_b7).numpy()\n",
        "b8 = tf.exp(model_tf_layered.raw_log_b8).numpy()\n",
        "b5_prime = tf.exp(model_tf_layered.raw_log_b5_prime).numpy()\n",
        "b6_prime = tf.exp(model_tf_layered.raw_log_b6_prime).numpy()\n",
        "b7_prime = tf.exp(model_tf_layered.raw_log_b7_prime).numpy()\n",
        "b8_prime = tf.exp(model_tf_layered.raw_log_b8_prime).numpy()\n",
        "\n",
        "\n",
        "# --- Print in a clean, organized table format ---\n",
        "print(f\"{'Parameter':<12} | {'Value':<15} | {'Parameter':<12} | {'Value'}\")\n",
        "print(\"-\" * 55)\n",
        "print(f\"{'k1':<12} | {k1:<15.5f} | {'i1':<12} | {i1:<15.5f}\")\n",
        "print(f\"{'k2':<12} | {k2:<15.5f} | {'i2':<12} | {i2:<15.5f}\")\n",
        "print(f\"{'k5':<12} | {k5:<15.5f} | {'i5':<12} | {i5:<15.5f}\")\n",
        "print(f\"{'k6':<12} | {k6:<15.5f} | {'i6':<12} | {i6:<15.5f}\")\n",
        "print(f\"{'k7':<12} | {k7:<15.5f} | {'i7':<12} | {i7:<15.5f}\")\n",
        "print(f\"{'k8':<12} | {k8:<15.5f} | {'i8':<12} | {i8:<15.5f}\")\n",
        "print(f\"{'k13':<12} | {k13:<15.5f} |\")\n",
        "print(f\"{'k14':<12} | {k14:<15.5f} |\")\n",
        "print(f\"{'k15':<12} | {k15:<15.5f} |\")\n",
        "print(f\"{'k16':<12} | {k16:<15.5f} |\")\n",
        "print(\"-\" * 55)\n",
        "print(f\"{'a1':<12} | {a1:<15.5f} | {'b5':<12} | {b5:<15.5f}\")\n",
        "print(f\"{'a2':<12} | {a2:<15.5f} | {'b6':<12} | {b6:<15.5f}\")\n",
        "print(f\"{'a5':<12} | {a5:<15.5f} | {'b7':<12} | {b7:<15.5f}\")\n",
        "print(f\"{'a6':<12} | {a6:<15.5f} | {'b8':<12} | {b8:<15.5f}\")\n",
        "print(f\"{'a7':<12} | {a7:<15.5f} | {'b5_prime':<12} | {b5_prime:<15.5f}\")\n",
        "print(f\"{'a8':<12} | {a8:<15.5f} | {'b6_prime':<12} | {b6_prime:<15.5f}\")\n",
        "print(f\"{'a5_prime':<12} | {a5_prime:<15.5f} | {'b7_prime':<12} | {b7_prime:<15.5f}\")\n",
        "print(f\"{'a6_prime':<12} | {a6_prime:<15.5f} | {'b8_prime':<12} | {b8_prime:<15.5f}\")\n",
        "print(f\"{'a7_prime':<12} | {a7_prime:<15.5f} |\")\n",
        "print(f\"{'a8_prime':<12} | {a8_prime:<15.5f} |\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfMgP0ChLHDT",
        "outputId": "4881f11f-bb92-41d1-f95d-ae96da65b22d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "      Final Learned Model Parameters (Raw Log Form)\n",
            "============================================================\n",
            "raw_log_k1          : 0.17093582\n",
            "raw_log_k2          : -0.00344529\n",
            "raw_log_i1          : 0.74075730\n",
            "raw_log_i2          : 0.82635462\n",
            "raw_log_a1          : -2.14519689\n",
            "raw_log_a2          : -2.30439274\n",
            "raw_log_k5          : 0.30099618\n",
            "raw_log_k6          : 0.05812556\n",
            "raw_log_i5          : -0.66980836\n",
            "raw_log_i6          : -0.45910360\n",
            "raw_log_a5          : -1.86701697\n",
            "raw_log_a6          : -1.89179693\n",
            "raw_log_a5_prime    : -1.32602770\n",
            "raw_log_a6_prime    : -1.55544085\n",
            "raw_log_k7          : 0.09625246\n",
            "raw_log_k8          : -0.20598582\n",
            "raw_log_i7          : 0.76586272\n",
            "raw_log_i8          : 0.84567122\n",
            "raw_log_a7          : -2.17438936\n",
            "raw_log_a8          : -2.35121530\n",
            "raw_log_a7_prime    : -1.53138357\n",
            "raw_log_a8_prime    : -1.89183098\n",
            "raw_log_k13         : -1.00146201\n",
            "raw_log_k14         : 1.23884718\n",
            "raw_log_b5          : -3.39466601\n",
            "raw_log_b6          : -2.87987646\n",
            "raw_log_b5_prime    : -2.96026576\n",
            "raw_log_b6_prime    : -2.19417918\n",
            "raw_log_k15         : -1.53517778\n",
            "raw_log_k16         : -0.39241336\n",
            "raw_log_b7          : -3.96974946\n",
            "raw_log_b8          : -1.63559996\n",
            "raw_log_b7_prime    : -3.27560229\n",
            "raw_log_b8_prime    : -0.57009475\n",
            "\n",
            "============================================================\n",
            "   Transformed Model Parameters (Physical Interpretable Values)\n",
            "============================================================\n",
            "Parameter    | Value           | Parameter    | Value\n",
            "-------------------------------------------------------\n",
            "k1           | 2.18641         | i1           | 3.09752        \n",
            "k2           | 2.49656         | i2           | 3.28497        \n",
            "k5           | 2.35120         | i5           | 1.51181        \n",
            "k6           | 2.55985         | i6           | 1.63185        \n",
            "k7           | 2.10104         | i7           | 3.15085        \n",
            "k8           | 2.31384         | i8           | 3.32954        \n",
            "k13          | 1.36734         |\n",
            "k14          | 4.95163         |\n",
            "k15          | 1.21542         |\n",
            "k16          | 2.17542         |\n",
            "-------------------------------------------------------\n",
            "a1           | 0.11704         | b5           | 0.03355        \n",
            "a2           | 0.09982         | b6           | 0.05614        \n",
            "a5           | 0.15458         | b7           | 0.01888        \n",
            "a6           | 0.15080         | b8           | 0.19484        \n",
            "a7           | 0.11368         | b5_prime     | 0.05181        \n",
            "a8           | 0.09525         | b6_prime     | 0.11145        \n",
            "a5_prime     | 0.26553         | b7_prime     | 0.03779        \n",
            "a6_prime     | 0.21110         | b8_prime     | 0.56547        \n",
            "a7_prime     | 0.21624         |\n",
            "a8_prime     | 0.15080         |\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "40QVKWsUdks1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}