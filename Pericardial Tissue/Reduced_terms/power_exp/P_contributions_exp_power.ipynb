{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow pandas scipy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6opHXe9NKr-",
        "outputId": "16359f9b-27f8-47e6-e59e-e6fd9304d4ba"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Collecting astunparse>=1.6.0 (from tensorflow)\n",
            "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
            "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Collecting google_pasta>=0.1.1 (from tensorflow)\n",
            "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
            "Collecting libclang>=13.0.0 (from tensorflow)\n",
            "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: opt_einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf>=5.28.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (6.32.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing_extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.74.0)\n",
            "Collecting tensorboard~=2.20.0 (from tensorflow)\n",
            "  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: keras>=3.10.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n",
            "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.10.0->tensorflow) (14.1.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.10.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard~=2.20.0->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.20.0->tensorflow) (11.3.0)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.20.0->tensorflow)\n",
            "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting werkzeug>=1.0.1 (from tensorboard~=2.20.0->tensorflow)\n",
            "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n",
            "Downloading tensorflow-2.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (620.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m620.7/620.7 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
            "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m80.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m117.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m116.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: libclang, flatbuffers, wheel, werkzeug, tensorboard-data-server, google_pasta, tensorboard, astunparse, tensorflow\n",
            "Successfully installed astunparse-1.6.3 flatbuffers-25.2.10 google_pasta-0.2.0 libclang-18.1.1 tensorboard-2.20.0 tensorboard-data-server-0.7.2 tensorflow-2.20.0 werkzeug-3.1.3 wheel-0.45.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "k5_YZgd3M5D0",
        "outputId": "584ea7d3-cee9-4df0-9cbb-81d72571d7f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: /CPU:0\n",
            "Training starts...\n",
            "E[100/4000], L1:5.623e+04, L2:3.003e+03, Tot:5.923e+04, LR:5.00e-04\n",
            "E[200/4000], L1:1.644e+04, L2:4.600e+02, Tot:1.690e+04, LR:5.00e-04\n",
            "E[300/4000], L1:1.050e+04, L2:1.843e+02, Tot:1.069e+04, LR:5.00e-04\n",
            "E[400/4000], L1:5.639e+03, L2:1.268e+02, Tot:5.766e+03, LR:5.00e-04\n",
            "E[500/4000], L1:2.746e+03, L2:1.902e+02, Tot:2.936e+03, LR:5.00e-04\n",
            "E[600/4000], L1:1.802e+03, L2:3.113e+02, Tot:2.114e+03, LR:5.00e-04\n",
            "E[700/4000], L1:1.636e+03, L2:3.204e+02, Tot:1.956e+03, LR:5.00e-04\n",
            "E[800/4000], L1:1.468e+03, L2:3.354e+02, Tot:1.803e+03, LR:5.00e-04\n",
            "E[900/4000], L1:1.291e+03, L2:3.586e+02, Tot:1.650e+03, LR:5.00e-04\n",
            "E[1000/4000], L1:1.136e+03, L2:3.783e+02, Tot:1.514e+03, LR:4.80e-04\n",
            "E[1100/4000], L1:9.650e+02, L2:4.050e+02, Tot:1.370e+03, LR:4.80e-04\n",
            "E[1200/4000], L1:7.965e+02, L2:4.388e+02, Tot:1.235e+03, LR:4.80e-04\n",
            "E[1300/4000], L1:6.318e+02, L2:4.815e+02, Tot:1.113e+03, LR:4.80e-04\n",
            "E[1400/4000], L1:4.996e+02, L2:5.213e+02, Tot:1.021e+03, LR:4.80e-04\n",
            "E[1500/4000], L1:3.980e+02, L2:5.565e+02, Tot:9.545e+02, LR:4.80e-04\n",
            "E[1600/4000], L1:3.595e+02, L2:5.657e+02, Tot:9.252e+02, LR:4.80e-04\n",
            "E[1700/4000], L1:3.491e+02, L2:5.636e+02, Tot:9.127e+02, LR:4.80e-04\n",
            "E[1800/4000], L1:3.428e+02, L2:5.604e+02, Tot:9.032e+02, LR:4.80e-04\n",
            "E[1900/4000], L1:3.382e+02, L2:5.555e+02, Tot:8.937e+02, LR:4.80e-04\n",
            "E[2000/4000], L1:3.371e+02, L2:5.488e+02, Tot:8.860e+02, LR:4.61e-04\n",
            "E[2100/4000], L1:3.393e+02, L2:5.398e+02, Tot:8.791e+02, LR:4.61e-04\n",
            "E[2200/4000], L1:3.416e+02, L2:5.305e+02, Tot:8.721e+02, LR:4.61e-04\n",
            "E[2300/4000], L1:3.446e+02, L2:5.202e+02, Tot:8.648e+02, LR:4.61e-04\n",
            "E[2400/4000], L1:3.480e+02, L2:5.091e+02, Tot:8.571e+02, LR:4.61e-04\n",
            "E[2500/4000], L1:3.526e+02, L2:4.966e+02, Tot:8.492e+02, LR:4.61e-04\n",
            "E[2600/4000], L1:3.587e+02, L2:4.824e+02, Tot:8.412e+02, LR:4.61e-04\n",
            "E[2700/4000], L1:3.662e+02, L2:4.671e+02, Tot:8.333e+02, LR:4.61e-04\n",
            "E[2800/4000], L1:3.714e+02, L2:4.538e+02, Tot:8.253e+02, LR:4.61e-04\n",
            "E[2900/4000], L1:3.833e+02, L2:4.348e+02, Tot:8.181e+02, LR:4.61e-04\n",
            "E[3000/4000], L1:3.913e+02, L2:4.217e+02, Tot:8.130e+02, LR:4.42e-04\n",
            "E[3100/4000], L1:3.967e+02, L2:4.115e+02, Tot:8.082e+02, LR:4.42e-04\n",
            "E[3200/4000], L1:4.033e+02, L2:4.015e+02, Tot:8.048e+02, LR:4.42e-04\n",
            "E[3300/4000], L1:4.055e+02, L2:3.965e+02, Tot:8.020e+02, LR:4.42e-04\n",
            "E[3400/4000], L1:4.066e+02, L2:3.921e+02, Tot:7.986e+02, LR:4.42e-04\n",
            "E[3500/4000], L1:4.094e+02, L2:3.866e+02, Tot:7.960e+02, LR:4.42e-04\n",
            "E[3600/4000], L1:4.107e+02, L2:3.830e+02, Tot:7.937e+02, LR:4.42e-04\n",
            "E[3700/4000], L1:4.121e+02, L2:3.794e+02, Tot:7.915e+02, LR:4.42e-04\n",
            "E[3800/4000], L1:4.128e+02, L2:3.766e+02, Tot:7.894e+02, LR:4.42e-04\n",
            "E[3900/4000], L1:4.138e+02, L2:3.734e+02, Tot:7.872e+02, LR:4.42e-04\n",
            "E[4000/4000], L1:4.148e+02, L2:3.704e+02, Tot:7.851e+02, LR:4.25e-04\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Calculating contributions for uniaxial...\n",
            "  - Calculated contribution for term: Pow(I1)\n",
            "  - Calculated contribution for term: Pow(I2)\n",
            "  - Calculated contribution for term: Exp(I1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function calculate_P11_task1_tf at 0x7d4f757bb880> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function calculate_P11_task1_tf at 0x7d4f757bb880> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  - Calculated contribution for term: Exp(I2)\n",
            "  - Calculated contribution for term: Pow(I4)\n",
            "  - Calculated contribution for term: Pow(I6)\n",
            "  - Calculated contribution for term: Exp(I4)\n",
            "  - Calculated contribution for term: Exp(I6)\n",
            "\n",
            "Calculating contributions for biaxial...\n",
            "  - Calculated contribution for term: Pow(I1)\n",
            "  - Calculated contribution for term: Pow(I2)\n",
            "  - Calculated contribution for term: Exp(I1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function calculate_P22_task2_tf_batch at 0x7d4f757bbec0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  - Calculated contribution for term: Exp(I2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function calculate_P22_task2_tf_batch at 0x7d4f757bbec0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  - Calculated contribution for term: Pow(I4)\n",
            "  - Calculated contribution for term: Pow(I6)\n",
            "  - Calculated contribution for term: Exp(I4)\n",
            "  - Calculated contribution for term: Exp(I6)\n",
            "\n",
            "Successfully saved stress contributions to 'P_contributions_exp_power.csv'\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from io import StringIO\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.io import savemat\n",
        "\n",
        "tf.keras.backend.set_floatx('float64')\n",
        "DEVICE = \"/GPU:0\" if tf.config.list_physical_devices('GPU') else \"/CPU:0\"\n",
        "print(f\"Using device: {DEVICE}\")\n",
        "\n",
        "ARG_CLIP_MIN = tf.constant(-10.0, dtype=tf.float64)\n",
        "ARG_CLIP_MAX = tf.constant(10.0, dtype=tf.float64)\n",
        "\n",
        "# --- Simplified Model for Exponential Power Terms Only ---\n",
        "class StrainEnergy_ExpPower(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__(name=\"StrainEnergy_ExpPower\")\n",
        "        # Power Law terms (I1, I2)\n",
        "        self.raw_log_k1=self.add_weight(name=\"raw_log_k1\",shape=(),dtype=tf.float64,initializer=tf.keras.initializers.RandomNormal(mean=0.0,stddev=0.01),trainable=True)\n",
        "        self.raw_log_k2=self.add_weight(name=\"raw_log_k2\",shape=(),dtype=tf.float64,initializer=tf.keras.initializers.RandomNormal(mean=0.0,stddev=0.01),trainable=True)\n",
        "        self.raw_log_i1=self.add_weight(name=\"raw_log_i1\",shape=(),dtype=tf.float64,initializer=tf.keras.initializers.RandomNormal(mean=0.0,stddev=0.01),trainable=True)\n",
        "        self.raw_log_i2=self.add_weight(name=\"raw_log_i2\",shape=(),dtype=tf.float64,initializer=tf.keras.initializers.RandomNormal(mean=0.0,stddev=0.01),trainable=True)\n",
        "        self.raw_log_a1=self.add_weight(name=\"raw_log_a1\",shape=(),dtype=tf.float64,initializer=tf.keras.initializers.Constant(tf.math.log(0.1)),trainable=True)\n",
        "        self.raw_log_a2=self.add_weight(name=\"raw_log_a2\",shape=(),dtype=tf.float64,initializer=tf.keras.initializers.Constant(tf.math.log(0.1)),trainable=True)\n",
        "\n",
        "        # Exponential with i terms (I1, I2)\n",
        "        self.raw_log_k3=self.add_weight(name=\"raw_log_k3\",shape=(),dtype=tf.float64,initializer=tf.keras.initializers.RandomNormal(mean=0.0,stddev=0.01),trainable=True)\n",
        "        self.raw_log_k4=self.add_weight(name=\"raw_log_k4\",shape=(),dtype=tf.float64,initializer=tf.keras.initializers.RandomNormal(mean=0.0,stddev=0.01),trainable=True)\n",
        "        self.raw_log_i3=self.add_weight(name=\"raw_log_i3\",shape=(),dtype=tf.float64,initializer=tf.keras.initializers.RandomNormal(mean=0.0,stddev=0.01),trainable=True)\n",
        "        self.raw_log_i4=self.add_weight(name=\"raw_log_i4\",shape=(),dtype=tf.float64,initializer=tf.keras.initializers.RandomNormal(mean=0.0,stddev=0.01),trainable=True)\n",
        "        self.raw_log_a3=self.add_weight(name=\"raw_log_a3\",shape=(),dtype=tf.float64,initializer=tf.keras.initializers.Constant(tf.math.log(0.1)),trainable=True)\n",
        "        self.raw_log_a4=self.add_weight(name=\"raw_log_a4\",shape=(),dtype=tf.float64,initializer=tf.keras.initializers.Constant(tf.math.log(0.1)),trainable=True)\n",
        "        self.raw_log_a3_prime=self.add_weight(name=\"raw_log_a3_prime\",shape=(),dtype=tf.float64,initializer=tf.keras.initializers.Constant(tf.math.log(0.2)),trainable=True)\n",
        "        self.raw_log_a4_prime=self.add_weight(name=\"raw_log_a4_prime\",shape=(),dtype=tf.float64,initializer=tf.keras.initializers.Constant(tf.math.log(0.2)),trainable=True)\n",
        "\n",
        "        # Power Law terms for I4, I6 (Identity Scaled)\n",
        "        self.raw_log_k9=self.add_weight(name=\"raw_log_k9\",shape=(),dtype=tf.float64,initializer=tf.keras.initializers.RandomNormal(mean=0.0,stddev=0.01),trainable=True)\n",
        "        self.raw_log_k10=self.add_weight(name=\"raw_log_k10\",shape=(),dtype=tf.float64,initializer=tf.keras.initializers.RandomNormal(mean=0.0,stddev=0.01),trainable=True)\n",
        "        self.raw_log_b1=self.add_weight(name=\"raw_log_b1\",shape=(),dtype=tf.float64,initializer=tf.keras.initializers.Constant(tf.math.log(0.01)),trainable=True)\n",
        "        self.raw_log_b2=self.add_weight(name=\"raw_log_b2\",shape=(),dtype=tf.float64,initializer=tf.keras.initializers.Constant(tf.math.log(0.01)),trainable=True)\n",
        "\n",
        "        # Exponential terms for I4, I6\n",
        "        self.raw_log_k11=self.add_weight(name=\"raw_log_k11\",shape=(),dtype=tf.float64,initializer=tf.keras.initializers.RandomNormal(mean=0.0,stddev=0.01),trainable=True)\n",
        "        self.raw_log_k12=self.add_weight(name=\"raw_log_k12\",shape=(),dtype=tf.float64,initializer=tf.keras.initializers.RandomNormal(mean=0.0,stddev=0.01),trainable=True)\n",
        "        self.raw_log_b3=self.add_weight(name=\"raw_log_b3\",shape=(),dtype=tf.float64,initializer=tf.keras.initializers.Constant(tf.math.log(0.1)),trainable=True)\n",
        "        self.raw_log_b4=self.add_weight(name=\"raw_log_b4\",shape=(),dtype=tf.float64,initializer=tf.keras.initializers.Constant(tf.math.log(0.1)),trainable=True)\n",
        "        self.raw_log_b3_prime=self.add_weight(name=\"raw_log_b3_prime\",shape=(),dtype=tf.float64,initializer=tf.keras.initializers.Constant(tf.math.log(0.2)),trainable=True)\n",
        "        self.raw_log_b4_prime=self.add_weight(name=\"raw_log_b4_prime\",shape=(),dtype=tf.float64,initializer=tf.keras.initializers.Constant(tf.math.log(0.2)),trainable=True)\n",
        "\n",
        "        self.three=tf.constant(3.0,dtype=tf.float64); self.one=tf.constant(1.0,dtype=tf.float64); self.pow_base_epsilon=tf.constant(1e-8,dtype=tf.float64)\n",
        "\n",
        "    def _term_power_law(self, I, k, i, c, ref_val): return c * tf.pow(tf.maximum(tf.pow(I, k) - tf.pow(ref_val, k), 0.0) + self.pow_base_epsilon, i)\n",
        "    def _term_exponential(self, I, k, i, ic, oc, ref_val): return oc * (tf.exp(tf.clip_by_value(ic * tf.pow(tf.maximum(tf.pow(I, k) - tf.pow(ref_val, k), 0.0) + self.pow_base_epsilon, i), ARG_CLIP_MIN, ARG_CLIP_MAX)) - 1.0)\n",
        "    def _term_identity_scaled(self, I, k, c, ref_val): return c * (tf.pow(I, k) - tf.pow(ref_val, k))\n",
        "    def _term_exponential_no_i(self, I, k, ic, oc, ref_val): return oc * (tf.exp(tf.clip_by_value(ic * (tf.pow(I, k) - tf.pow(ref_val, k)), ARG_CLIP_MIN, ARG_CLIP_MAX)) - 1.0)\n",
        "\n",
        "    def call(self, I1, I2, I4, I6):\n",
        "        k1=1.0+tf.exp(self.raw_log_k1); k2=1.5+tf.exp(self.raw_log_k2); k3=1.0+tf.exp(self.raw_log_k3); k4=1.5+tf.exp(self.raw_log_k4)\n",
        "        i1=1.0+tf.exp(self.raw_log_i1); i2=1.0+tf.exp(self.raw_log_i2); i3=1.0+tf.exp(self.raw_log_i3); i4=1.0+tf.exp(self.raw_log_i4)\n",
        "        a1=tf.exp(self.raw_log_a1); a2=tf.exp(self.raw_log_a2); a3=tf.exp(self.raw_log_a3); a4=tf.exp(self.raw_log_a4)\n",
        "        a3_prime=tf.exp(self.raw_log_a3_prime); a4_prime=tf.exp(self.raw_log_a4_prime)\n",
        "        k9=1.0+tf.exp(self.raw_log_k9); k10=1.5+tf.exp(self.raw_log_k10); k11=1.0+tf.exp(self.raw_log_k11); k12=1.5+tf.exp(self.raw_log_k12)\n",
        "        b1=tf.exp(self.raw_log_b1); b2=tf.exp(self.raw_log_b2); b3=tf.exp(self.raw_log_b3); b4=tf.exp(self.raw_log_b4)\n",
        "        b3_prime=tf.exp(self.raw_log_b3_prime); b4_prime=tf.exp(self.raw_log_b4_prime)\n",
        "\n",
        "        W = tf.zeros_like(I1, dtype=tf.float64)\n",
        "        W += self._term_power_law(I1, k1, i1, a1, self.three)\n",
        "        W += self._term_power_law(I2, k2, i2, a2, self.three)\n",
        "        W += self._term_exponential(I1, k3, i3, a3_prime, a3, self.three)\n",
        "        W += self._term_exponential(I2, k4, i4, a4_prime, a4, self.three)\n",
        "        W += self._term_identity_scaled(I4, k9, b1, self.one)\n",
        "        W += self._term_identity_scaled(I6, k10, b2, self.one)\n",
        "        W += self._term_exponential_no_i(I4, k11, b3_prime, b3, self.one)\n",
        "        W += self._term_exponential_no_i(I6, k12, b4_prime, b4, self.one)\n",
        "        return W\n",
        "\n",
        "# ... (All the original stress calculation functions remain the same) ...\n",
        "# ... (get_invariants_tf, get_W_and_gradients_tf, calculate_P11_task1_tf, etc.) ...\n",
        "@tf.function\n",
        "def get_invariants_tf(lambda1,lambda2,lambda3):\n",
        "    min_lambda_val=tf.constant(1e-4,dtype=tf.float64); lambda1=tf.maximum(lambda1,min_lambda_val); lambda2=tf.maximum(lambda2,min_lambda_val); lambda3=tf.maximum(lambda3,min_lambda_val); l1s=tf.pow(lambda1,2.0); l2s=tf.pow(lambda2,2.0); l3s=tf.pow(lambda3,2.0)\n",
        "    I1=l1s+l2s+l3s; I2=tf.pow(lambda1*lambda2,2.0)+tf.pow(lambda2*lambda3,2.0)+tf.pow(lambda3*lambda1,2.0); I4=l1s; I6=tf.pow(lambda1,-2.0)\n",
        "    return I1,I2,I4,I6\n",
        "@tf.function\n",
        "def get_W_and_gradients_tf(l1t,l2t,l3t,model, W_func):\n",
        "    with tf.GradientTape(watch_accessed_variables=False) as tape:\n",
        "        tape.watch([l1t, l2t, l3t]); I1, I2, I4, I6 = get_invariants_tf(l1t, l2t, l3t); W_val = W_func(I1, I2, I4, I6)\n",
        "    grads = tape.gradient(W_val, [l1t, l2t, l3t]); dWdl1 = grads[0] if grads[0] is not None else tf.zeros_like(l1t); dWdl2 = grads[1] if grads[1] is not None else tf.zeros_like(l2t); dWdl3 = grads[2] if grads[2] is not None else tf.zeros_like(l3t)\n",
        "    return W_val, dWdl1, dWdl2, dWdl3\n",
        "@tf.function\n",
        "def _calculate_raw_P11_task1_tf(l1vst, model, W_func):\n",
        "    l1t = tf.maximum(l1vst, tf.constant(1e-4, dtype=tf.float64))\n",
        "    l2t = tf.pow(l1t, -0.5)\n",
        "    l3t = tf.pow(l1t, -0.5)\n",
        "    _, dWdl1, _, dWdl3 = get_W_and_gradients_tf(l1t, l2t, l3t, model, W_func)\n",
        "    Ph = l3t * dWdl3\n",
        "    safe_l1t = tf.maximum(l1t, tf.constant(1e-6, dtype=tf.float64))\n",
        "    return (dWdl1 - Ph / safe_l1t) / 7.5\n",
        "@tf.function\n",
        "def calculate_P11_task1_tf(l1vst, model, W_func):\n",
        "    p11_raw = _calculate_raw_P11_task1_tf(l1vst, model, W_func)\n",
        "    p11_offset = _calculate_raw_P11_task1_tf(tf.constant([1.0], dtype=tf.float64), model, W_func)\n",
        "    return p11_raw - p11_offset\n",
        "\n",
        "@tf.function\n",
        "def sigma11_for_root_tf(lambda1_trial_t, lambda2_fixed_t_tensor, model, W_func):\n",
        "    lambda1_trial_t_stable = tf.maximum(lambda1_trial_t, tf.constant(1e-4, dtype=tf.float64)); lambda2_fixed_t_stable = tf.maximum(lambda2_fixed_t_tensor, tf.constant(1e-4, dtype=tf.float64))\n",
        "    safe_denom_prod = tf.maximum(lambda1_trial_t_stable * lambda2_fixed_t_stable, tf.constant(1e-6, dtype=tf.float64)); lambda3_trial_t = (1.0 / safe_denom_prod)\n",
        "    _, dW_dlambda1, _, dW_dlambda3 = get_W_and_gradients_tf(lambda1_trial_t_stable, lambda2_fixed_t_stable, lambda3_trial_t, model, W_func); P_hydro = lambda3_trial_t * dW_dlambda3\n",
        "    safe_lambda1_trial_t_stable = tf.maximum(lambda1_trial_t_stable, tf.constant(1e-6, dtype=tf.float64)); return (dW_dlambda1 - P_hydro / safe_lambda1_trial_t_stable)\n",
        "\n",
        "@tf.function\n",
        "def find_lambda1_newton_tf(lambda2_val_scalar_tensor, model, W_func, initial_lambda1_guess=1.0, iterations=tf.constant(10, dtype=tf.int32), tol=1e-7):\n",
        "    min_lambda_val_newton=tf.constant(0.2,dtype=tf.float64); max_lambda_val_newton=tf.constant(3.0,dtype=tf.float64); max_step_lambda=tf.constant(0.1,dtype=tf.float64)\n",
        "    loop_vars = [tf.constant(0, dtype=tf.int32), initial_lambda1_guess, tf.constant(False, dtype=tf.bool)]\n",
        "    def cond(i, _, converged): return tf.logical_and(i < iterations, tf.logical_not(converged))\n",
        "    def body(i, current_lambda, _):\n",
        "        with tf.GradientTape(watch_accessed_variables=False) as tape:\n",
        "            tape.watch(current_lambda); sigma11 = sigma11_for_root_tf(current_lambda, lambda2_val_scalar_tensor, model, W_func)\n",
        "        grad = tape.gradient(sigma11, current_lambda); newly_converged = tf.abs(sigma11) < tol\n",
        "        problem = grad is None or tf.math.is_nan(grad) or tf.math.is_inf(grad)\n",
        "        def update_lambda():\n",
        "            delta = sigma11 / (grad + tf.constant(1e-8, dtype=tf.float64) * tf.sign(grad)); problem_delta = tf.math.is_nan(delta) or tf.math.is_inf(delta)\n",
        "            safe_delta = tf.cond(problem_delta, lambda: tf.constant(0.0, dtype=tf.float64), lambda: delta); clipped_delta = tf.clip_by_value(safe_delta, -max_step_lambda, max_step_lambda)\n",
        "            return tf.clip_by_value(current_lambda - clipped_delta, min_lambda_val_newton, max_lambda_val_newton)\n",
        "        next_lambda = tf.cond(problem, lambda: current_lambda, update_lambda); return [i + 1, next_lambda, tf.logical_or(newly_converged, problem)]\n",
        "    _, final_lambda, _ = tf.while_loop(cond, body, loop_vars); return final_lambda\n",
        "\n",
        "@tf.function\n",
        "def _calculate_raw_P22_task2_tf(lambda2_val_scalar_tensor, model, W_func):\n",
        "    lambda2_stable = tf.maximum(lambda2_val_scalar_tensor, tf.constant(1e-4, dtype=tf.float64))\n",
        "    initial_lambda1_guess = 1.0 / tf.sqrt(lambda2_stable)\n",
        "    lambda1_root_t = find_lambda1_newton_tf(lambda2_stable, model, W_func, initial_lambda1_guess)\n",
        "    lambda1_root_t_stable = tf.maximum(lambda1_root_t, tf.constant(1e-4, dtype=tf.float64))\n",
        "    safe_denom = tf.maximum(lambda1_root_t_stable * lambda2_stable, tf.constant(1e-6, dtype=tf.float64))\n",
        "    lambda3_calc_t = (1.0 / safe_denom)\n",
        "    _, _, dWdl2, dWdl3 = get_W_and_gradients_tf(lambda1_root_t_stable, lambda2_stable, lambda3_calc_t, model, W_func)\n",
        "    Ph = lambda3_calc_t * dWdl3\n",
        "    safe_lambda2_calc_t = tf.maximum(lambda2_stable, tf.constant(1e-6, dtype=tf.float64))\n",
        "    return (dWdl2 - Ph / safe_lambda2_calc_t) / 50\n",
        "@tf.function\n",
        "def calculate_P22_task2_tf_batch(lambda2_batch, model, W_func):\n",
        "    p22_raw_batch = tf.scan(lambda _, l2: _calculate_raw_P22_task2_tf(l2, model, W_func), lambda2_batch, initializer=tf.constant(0.0, dtype=tf.float64))\n",
        "    p22_offset = _calculate_raw_P22_task2_tf(tf.constant(1.0, dtype=tf.float64), model, W_func)\n",
        "    return p22_raw_batch - p22_offset\n",
        "\n",
        "# ... (Data Loading and Normalization remain the same) ...\n",
        "exp_data_raw_uniaxial_cnf=np.array([[1.1986196319018403,1.285990338164251],[1.18680981595092,0.9768115942028984],[1.1699386503067484,0.638647342995169],[1.1483128834355827,0.29275362318840586],[1.1153374233128834,0.08502415458937207],[1.0725460122699388,0.018357487922705418],[1.040184049079755,0.00869565217391316],[1.0157975460122703,0.0019323671497585848],[1.0,0.0]])\n",
        "lambda1_data_task1_np=exp_data_raw_uniaxial_cnf[:,0]; P11_data_task1_np=exp_data_raw_uniaxial_cnf[:,1]\n",
        "csv_content_cnf=\"lambda,stress\\n1.1917177914110426,0.16038647342995177\\n1.1464723926380367,0.056038647342995296\\n1.108435582822086,0.028019323671497676\\n1.071472392638037,0.013526570048309317\\n1.038343558282209,0.006763285024154686\\n1.0,0.0\\n\"\n",
        "df_task2=pd.read_csv(StringIO(csv_content_cnf)); lambda2_data_task2_np=df_task2['lambda'].values; P22_data_task2_np=df_task2['stress'].values\n",
        "stress_scale = max(np.max(P11_data_task1_np), np.max(P22_data_task2_np))\n",
        "P11_data_task1_norm_np = P11_data_task1_np / stress_scale\n",
        "P22_data_task2_norm_np = P22_data_task2_np / stress_scale\n",
        "stress_scale_tf = tf.constant(stress_scale, dtype=tf.float64)\n",
        "lambda1_data_task1_tf=tf.constant(lambda1_data_task1_np,dtype=tf.float64)\n",
        "P11_data_task1_norm_tf=tf.constant(P11_data_task1_norm_np,dtype=tf.float64)\n",
        "lambda2_data_task2_tf=tf.constant(lambda2_data_task2_np,dtype=tf.float64)\n",
        "P22_data_task2_norm_tf=tf.constant(P22_data_task2_norm_np,dtype=tf.float64)\n",
        "\n",
        "# --- Model, Optimizer, and Training Setup remain the same ---\n",
        "model_tf_layered = StrainEnergy_ExpPower()\n",
        "L2_REG_STRENGTH = tf.constant(1e-12, dtype=tf.float64)\n",
        "POSITIVITY_PENALTY_STRENGTH = tf.constant(5e4, dtype=tf.float64)\n",
        "initial_learning_rate = 5e-4\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate, decay_steps=1000, decay_rate=0.96, staircase=True)\n",
        "optimizer_tf = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "\n",
        "@tf.function\n",
        "def train_step_final(l1_batch, p11_batch_norm, l2_batch, p22_batch_norm, model, scale_factor, l2_reg, pos_penalty_strength):\n",
        "    with tf.GradientTape() as tape:\n",
        "        p11_pred = calculate_P11_task1_tf(l1_batch, model, model.call)\n",
        "        p22_pred = calculate_P22_task2_tf_batch(l2_batch, model, model.call)\n",
        "\n",
        "        p11_pred_norm = p11_pred / scale_factor\n",
        "        p22_pred_norm = p22_pred / scale_factor\n",
        "\n",
        "        loss1_weight = 2500000.0\n",
        "        loss2_weight = 10000000.0\n",
        "        loss1 = tf.reduce_mean(tf.square(p11_batch_norm - p11_pred_norm)) * loss1_weight\n",
        "        loss2 = tf.reduce_mean(tf.square(p22_batch_norm - p22_pred_norm)) * loss2_weight\n",
        "\n",
        "        positivity_loss_1 = tf.reduce_mean(tf.nn.relu(-p11_pred))\n",
        "        positivity_loss_2 = tf.reduce_mean(tf.nn.relu(-p22_pred))\n",
        "        l2_loss = tf.add_n([tf.nn.l2_loss(v) for v in model.trainable_variables])\n",
        "        total_loss = (loss1 + loss2 +\n",
        "                      l2_reg * l2_loss +\n",
        "                      pos_penalty_strength * (positivity_loss_1 + positivity_loss_2))\n",
        "    t_vars = model.trainable_variables\n",
        "    grads = tape.gradient(total_loss, t_vars)\n",
        "    optimizer_tf.apply_gradients(zip([tf.clip_by_norm(g, 1.0) if g is not None else tf.zeros_like(v) for g, v in zip(grads, t_vars)], t_vars))\n",
        "    return loss1, loss2, total_loss\n",
        "\n",
        "# --- Training Loop remains the same ---\n",
        "epochs=4000\n",
        "dI1=tf.constant([3.0],dtype=tf.float64); dI2=tf.constant([3.0],dtype=tf.float64); dI4=tf.constant([1.0],dtype=tf.float64); dI6=tf.constant([1.e-6],dtype=tf.float64)\n",
        "_=model_tf_layered(dI1,dI2,dI4,dI6)\n",
        "print(\"Training starts...\");\n",
        "for e in range(epochs):\n",
        "    l1,l2,tl=train_step_final(lambda1_data_task1_tf, P11_data_task1_norm_tf, lambda2_data_task2_tf, P22_data_task2_norm_tf,\n",
        "                              model_tf_layered, stress_scale_tf, L2_REG_STRENGTH, POSITIVITY_PENALTY_STRENGTH)\n",
        "    if (e+1)%100==0:\n",
        "        current_lr = lr_schedule(optimizer_tf.iterations).numpy()\n",
        "        print(f\"E[{e+1}/{epochs}], L1:{l1.numpy():.3e}, L2:{l2.numpy():.3e}, Tot:{tl.numpy():.3e}, LR:{current_lr:.2e}\")\n",
        "\n",
        "# ... (Standard plotting code remains the same) ...\n",
        "# The data for plotting is generated here\n",
        "l1_plot = np.linspace(lambda1_data_task1_np.min(), lambda1_data_task1_np.max(), 100)\n",
        "p11_plot = calculate_P11_task1_tf(tf.constant(l1_plot, dtype=tf.float64), model_tf_layered, model_tf_layered.call).numpy()\n",
        "l2_plot = np.linspace(lambda2_data_task2_np.min(), lambda2_data_task2_np.max(), 100)\n",
        "p22_plot = calculate_P22_task2_tf_batch(tf.constant(l2_plot, dtype=tf.float64), model_tf_layered, model_tf_layered.call).numpy()\n",
        "\n",
        "# Plotting the final results\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.scatter(lambda1_data_task1_np, P11_data_task1_np, c='b', label='Actual P11')\n",
        "plt.plot(l1_plot, p11_plot, c='r', label='Predicted P11')\n",
        "plt.scatter(lambda2_data_task2_np, P22_data_task2_np, c='g', marker='x', label='Actual P22')\n",
        "plt.plot(l2_plot, p22_plot, c='orange', label='Predicted P22')\n",
        "plt.legend(); plt.grid(True); plt.xlabel(r\"$\\lambda$\"); plt.ylabel(\"Stress\"); plt.show()\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# ===== NEW SECTION: CALCULATE AND SAVE STRESS CONTRIBUTIONS ===================\n",
        "# ==============================================================================\n",
        "\n",
        "def get_model_terms_exp_power(model):\n",
        "    \"\"\"Returns a dictionary of individual W term functions for the Exp-Power model.\"\"\"\n",
        "    k1=1.0+tf.exp(model.raw_log_k1); k2=1.5+tf.exp(model.raw_log_k2); k3=1.0+tf.exp(model.raw_log_k3); k4=1.5+tf.exp(model.raw_log_k4)\n",
        "    i1=1.0+tf.exp(model.raw_log_i1); i2=1.0+tf.exp(model.raw_log_i2); i3=1.0+tf.exp(model.raw_log_i3); i4=1.0+tf.exp(model.raw_log_i4)\n",
        "    a1=tf.exp(model.raw_log_a1); a2=tf.exp(model.raw_log_a2); a3=tf.exp(model.raw_log_a3); a4=tf.exp(model.raw_log_a4)\n",
        "    a3_prime=tf.exp(model.raw_log_a3_prime); a4_prime=tf.exp(model.raw_log_a4_prime)\n",
        "    k9=1.0+tf.exp(model.raw_log_k9); k10=1.5+tf.exp(model.raw_log_k10); k11=1.0+tf.exp(model.raw_log_k11); k12=1.5+tf.exp(model.raw_log_k12)\n",
        "    b1=tf.exp(model.raw_log_b1); b2=tf.exp(model.raw_log_b2); b3=tf.exp(model.raw_log_b3); b4=tf.exp(model.raw_log_b4)\n",
        "    b3_prime=tf.exp(model.raw_log_b3_prime); b4_prime=tf.exp(model.raw_log_b4_prime)\n",
        "\n",
        "    terms = {\n",
        "        \"Pow(I1)\":   lambda I1, I2, I4, I6: model._term_power_law(I1, k1, i1, a1, model.three),\n",
        "        \"Pow(I2)\":   lambda I1, I2, I4, I6: model._term_power_law(I2, k2, i2, a2, model.three),\n",
        "        \"Exp(I1)\":   lambda I1, I2, I4, I6: model._term_exponential(I1, k3, i3, a3_prime, a3, model.three),\n",
        "        \"Exp(I2)\":   lambda I1, I2, I4, I6: model._term_exponential(I2, k4, i4, a4_prime, a4, model.three),\n",
        "        \"Pow(I4)\":   lambda I1, I2, I4, I6: model._term_identity_scaled(I4, k9, b1, model.one),\n",
        "        \"Pow(I6)\":   lambda I1, I2, I4, I6: model._term_identity_scaled(I6, k10, b2, model.one),\n",
        "        \"Exp(I4)\":   lambda I1, I2, I4, I6: model._term_exponential_no_i(I4, k11, b3_prime, b3, model.one),\n",
        "        \"Exp(I6)\":   lambda I1, I2, I4, I6: model._term_exponential_no_i(I6, k12, b4_prime, b4, model.one),\n",
        "    }\n",
        "    return terms\n",
        "\n",
        "def calculate_stress_contributions(lambda_values, model, task_type):\n",
        "    \"\"\"Calculates the stress contribution of each term in the model.\"\"\"\n",
        "    terms = get_model_terms_exp_power(model)\n",
        "    contributions = {}\n",
        "\n",
        "    print(f\"\\nCalculating contributions for {task_type}...\")\n",
        "\n",
        "    for name, W_func in terms.items():\n",
        "        if task_type == 'uniaxial':\n",
        "            stress_contribution = calculate_P11_task1_tf(lambda_values, model, W_func)\n",
        "        elif task_type == 'biaxial':\n",
        "            stress_contribution = calculate_P22_task2_tf_batch(lambda_values, model, W_func)\n",
        "        else:\n",
        "            raise ValueError(\"task_type must be 'uniaxial' or 'biaxial'\")\n",
        "\n",
        "        contributions[name] = stress_contribution.numpy()\n",
        "        print(f\"  - Calculated contribution for term: {name}\")\n",
        "\n",
        "    return contributions\n",
        "\n",
        "# Define smooth lambda ranges for plotting\n",
        "lambda1_plot_tf = tf.constant(np.linspace(1.0, 1.2, 100), dtype=tf.float64)\n",
        "lambda2_plot_tf = tf.constant(np.linspace(1.0, 1.2, 100), dtype=tf.float64)\n",
        "\n",
        "# Calculate contributions for both tasks\n",
        "p11_contributions = calculate_stress_contributions(lambda1_plot_tf, model_tf_layered, 'uniaxial')\n",
        "p22_contributions = calculate_stress_contributions(lambda2_plot_tf, model_tf_layered, 'biaxial')\n",
        "\n",
        "# Create a single DataFrame to hold all the data\n",
        "df_contrib = pd.DataFrame()\n",
        "df_contrib['lambda1'] = lambda1_plot_tf.numpy()\n",
        "for name, values in p11_contributions.items():\n",
        "    df_contrib[f'P11_{name}'] = values\n",
        "\n",
        "df_contrib['lambda2'] = lambda2_plot_tf.numpy()\n",
        "for name, values in p22_contributions.items():\n",
        "    df_contrib[f'P22_{name}'] = values\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "output_filename = 'P_contributions_exp_power.csv'\n",
        "df_contrib.to_csv(output_filename, index=False)\n",
        "\n",
        "print(f\"\\nSuccessfully saved stress contributions to '{output_filename}'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# ===== NEW SECTION: EXTRACT AND PRINT FINAL LEARNED PARAMETERS ==============\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"      Final Learned Model Parameters (Raw Log Form)\")\n",
        "print(\"=\"*60)\n",
        "for v in model_tf_layered.trainable_variables:\n",
        "    print(f\"{v.name:20s}: {v.numpy():.8f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"   Transformed Model Parameters (Physical Interpretable Values)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# --- Extract and Transform Parameters specific to the Exp-Power model ---\n",
        "k1 = 1.0 + tf.exp(model_tf_layered.raw_log_k1).numpy()\n",
        "k2 = 1.5 + tf.exp(model_tf_layered.raw_log_k2).numpy()\n",
        "k3 = 1.0 + tf.exp(model_tf_layered.raw_log_k3).numpy()\n",
        "k4 = 1.5 + tf.exp(model_tf_layered.raw_log_k4).numpy()\n",
        "i1 = 1.0 + tf.exp(model_tf_layered.raw_log_i1).numpy()\n",
        "i2 = 1.0 + tf.exp(model_tf_layered.raw_log_i2).numpy()\n",
        "i3 = 1.0 + tf.exp(model_tf_layered.raw_log_i3).numpy()\n",
        "i4 = 1.0 + tf.exp(model_tf_layered.raw_log_i4).numpy()\n",
        "a1 = tf.exp(model_tf_layered.raw_log_a1).numpy()\n",
        "a2 = tf.exp(model_tf_layered.raw_log_a2).numpy()\n",
        "a3 = tf.exp(model_tf_layered.raw_log_a3).numpy()\n",
        "a4 = tf.exp(model_tf_layered.raw_log_a4).numpy()\n",
        "a3_prime = tf.exp(model_tf_layered.raw_log_a3_prime).numpy()\n",
        "a4_prime = tf.exp(model_tf_layered.raw_log_a4_prime).numpy()\n",
        "\n",
        "k9 = 1.0 + tf.exp(model_tf_layered.raw_log_k9).numpy()\n",
        "k10 = 1.5 + tf.exp(model_tf_layered.raw_log_k10).numpy()\n",
        "k11 = 1.0 + tf.exp(model_tf_layered.raw_log_k11).numpy()\n",
        "k12 = 1.5 + tf.exp(model_tf_layered.raw_log_k12).numpy()\n",
        "b1 = tf.exp(model_tf_layered.raw_log_b1).numpy()\n",
        "b2 = tf.exp(model_tf_layered.raw_log_b2).numpy()\n",
        "b3 = tf.exp(model_tf_layered.raw_log_b3).numpy()\n",
        "b4 = tf.exp(model_tf_layered.raw_log_b4).numpy()\n",
        "b3_prime = tf.exp(model_tf_layered.raw_log_b3_prime).numpy()\n",
        "b4_prime = tf.exp(model_tf_layered.raw_log_b4_prime).numpy()\n",
        "\n",
        "\n",
        "# --- Print in a clean, organized table format ---\n",
        "print(f\"{'Parameter':<12} | {'Value':<15} | {'Parameter':<12} | {'Value'}\")\n",
        "print(\"-\" * 55)\n",
        "print(f\"{'k1':<12} | {k1:<15.5f} | {'i1':<12} | {i1:<15.5f}\")\n",
        "print(f\"{'k2':<12} | {k2:<15.5f} | {'i2':<12} | {i2:<15.5f}\")\n",
        "print(f\"{'k3':<12} | {k3:<15.5f} | {'i3':<12} | {i3:<15.5f}\")\n",
        "print(f\"{'k4':<12} | {k4:<15.5f} | {'i4':<12} | {i4:<15.5f}\")\n",
        "print(f\"{'k9':<12} | {k9:<15.5f} |\")\n",
        "print(f\"{'k10':<12} | {k10:<15.5f} |\")\n",
        "print(f\"{'k11':<12} | {k11:<15.5f} |\")\n",
        "print(f\"{'k12':<12} | {k12:<15.5f} |\")\n",
        "print(\"-\" * 55)\n",
        "print(f\"{'a1':<12} | {a1:<15.5f} | {'b1':<12} | {b1:<15.5f}\")\n",
        "print(f\"{'a2':<12} | {a2:<15.5f} | {'b2':<12} | {b2:<15.5f}\")\n",
        "print(f\"{'a3':<12} | {a3:<15.5f} | {'b3':<12} | {b3:<15.5f}\")\n",
        "print(f\"{'a4':<12} | {a4:<15.5f} | {'b4':<12} | {b4:<15.5f}\")\n",
        "print(f\"{'a3_prime':<12} | {a3_prime:<15.5f} | {'b3_prime':<12} | {b3_prime:<15.5f}\")\n",
        "print(f\"{'a4_prime':<12} | {a4_prime:<15.5f} | {'b4_prime':<12} | {b4_prime:<15.5f}\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09WOTe9FNAdk",
        "outputId": "043f0dbc-db4a-4860-a55a-0b9c865fde32"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "      Final Learned Model Parameters (Raw Log Form)\n",
            "============================================================\n",
            "raw_log_k1          : 0.19533144\n",
            "raw_log_k2          : 0.01073746\n",
            "raw_log_i1          : 0.73819987\n",
            "raw_log_i2          : 0.81116630\n",
            "raw_log_a1          : -2.10893800\n",
            "raw_log_a2          : -2.30708074\n",
            "raw_log_k3          : 0.03577761\n",
            "raw_log_k4          : -0.28774260\n",
            "raw_log_i3          : 0.72781432\n",
            "raw_log_i4          : 0.82057515\n",
            "raw_log_a3          : -2.14689528\n",
            "raw_log_a4          : -2.45545882\n",
            "raw_log_a3_prime    : -1.58600504\n",
            "raw_log_a4_prime    : -1.92812811\n",
            "raw_log_k9          : -1.65395901\n",
            "raw_log_k10         : -0.34038328\n",
            "raw_log_b1          : -6.27633456\n",
            "raw_log_b2          : -3.81934110\n",
            "raw_log_k11         : -1.53741196\n",
            "raw_log_k12         : -0.27122692\n",
            "raw_log_b3          : -3.97074946\n",
            "raw_log_b4          : -1.61552649\n",
            "raw_log_b3_prime    : -3.27560229\n",
            "raw_log_b4_prime    : -1.21134448\n",
            "\n",
            "============================================================\n",
            "   Transformed Model Parameters (Physical Interpretable Values)\n",
            "============================================================\n",
            "Parameter    | Value           | Parameter    | Value\n",
            "-------------------------------------------------------\n",
            "k1           | 2.21571         | i1           | 3.09217        \n",
            "k2           | 2.51080         | i2           | 3.25053        \n",
            "k3           | 2.03643         | i3           | 3.07055        \n",
            "k4           | 2.24995         | i4           | 3.27181        \n",
            "k9           | 1.19129         |\n",
            "k10          | 2.21150         |\n",
            "k11          | 1.21494         |\n",
            "k12          | 2.26244         |\n",
            "-------------------------------------------------------\n",
            "a1           | 0.12137         | b1           | 0.00188        \n",
            "a2           | 0.09955         | b2           | 0.02194        \n",
            "a3           | 0.11685         | b3           | 0.01886        \n",
            "a4           | 0.08582         | b4           | 0.19879        \n",
            "a3_prime     | 0.20474         | b3_prime     | 0.03779        \n",
            "a4_prime     | 0.14542         | b4_prime     | 0.29780        \n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MG37DRphee9z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}